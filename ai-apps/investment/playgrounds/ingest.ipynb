{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d169cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import onnxruntime as ort\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.intra_op_num_threads = 8\n",
    "sess_options.inter_op_num_threads = 8\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import VectorParams, Distance, SparseVectorParams\n",
    "\n",
    "collection_name = \"news\"\n",
    "\n",
    "if not client.collection_exists(collection_name):\n",
    "   client.create_collection(\n",
    "      collection_name=collection_name,\n",
    "      vectors_config={\n",
    "         \"dense\": VectorParams(size=1024, distance=Distance.COSINE),\n",
    "         \"late\": models.VectorParams(\n",
    "            size=96,\n",
    "            distance=models.Distance.COSINE,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM,\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0)\n",
    "        ),\n",
    "      },\n",
    "      sparse_vectors_config={\n",
    "         \"splade\": SparseVectorParams(modifier=\"idf\")\n",
    "      }\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6820730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import LateInteractionTextEmbedding \n",
    "\n",
    "late_model = LateInteractionTextEmbedding(\"answerdotai/answerai-colbert-small-v1\")\n",
    "\n",
    "def batch_embeddings_late(contents: list[str]):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(contents), 100):\n",
    "        batch = contents[i:i+100]\n",
    "        embeddings = list(late_model.passage_embed(batch))\n",
    "        all_embeddings.extend(embeddings)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309bb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastembed import TextEmbedding\n",
    "\n",
    "# dense_model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v3\")\n",
    "\n",
    "# def batch_embeddings_dense(contents: list[str]):\n",
    "#     all_embeddings = []\n",
    "    \n",
    "#     for i in range(0, len(contents), 100):\n",
    "#         batch = contents[i:i+100]\n",
    "#         embeddings = list(dense_model.passage_embed(batch))\n",
    "#         all_embeddings.extend(embeddings)\n",
    "    \n",
    "#     return all_embeddings\n",
    "\n",
    "import voyageai\n",
    "\n",
    "vo = voyageai.Client()\n",
    "\n",
    "def batch_embeddings_dense(contents: list[str]):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(contents), 100):\n",
    "        batch = contents[i:i+100]\n",
    "        embeddings = vo.embed(batch, model=\"voyage-finance-2\", output_dimension=1024, truncation=True)\n",
    "        all_embeddings.extend(embeddings.embeddings)\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "SparseTextEmbedding.list_supported_models()\n",
    "\n",
    "sparse_model = SparseTextEmbedding(model_name=\"Qdrant/bm42-all-minilm-l6-v2-attentions\")\n",
    "\n",
    "def batch_embeddings_sparse(contents: list[str]):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    for i in range(0, len(contents), 100):\n",
    "        batch = contents[i:i+100]\n",
    "        embeddings = list(sparse_model.passage_embed(batch))\n",
    "        all_embeddings.extend(embeddings)\n",
    "    \n",
    "    return all_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def load_json_files_to_array(folder_path):\n",
    "    json_array = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                    json_array.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    return json_array\n",
    "\n",
    "rawData = load_json_files_to_array(\"ai-apps/investment/dataset/stockbit-snips/processed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "for idx, doc in enumerate(rawData[start_idx:]):\n",
    "    print(f\"processing doc {idx+start_idx}\")\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    for news in doc[\"marketNews\"]:\n",
    "        news[\"publishDate\"] = doc[\"publishDate\"]\n",
    "        news[\"type\"] = \"market-news\"\n",
    "        chunks.append(news)\n",
    "\n",
    "    for news in doc[\"tickerNews\"]:\n",
    "        news[\"publishDate\"] = doc[\"publishDate\"]\n",
    "        news[\"type\"] = \"ticker-news\"\n",
    "        chunks.append(news)\n",
    "\n",
    "    chunk_contents = [f\"{c['title']}\\n{c['content']}\" for c in chunks]\n",
    "\n",
    "    # print(\"embedding dense start\")\n",
    "    chunk_embeddings = batch_embeddings_dense(chunk_contents)\n",
    "    # print(\"embedding dense end\")\n",
    "\n",
    "    sparse_embeddings = batch_embeddings_sparse(chunk_contents)\n",
    "\n",
    "    late_embeddings = batch_embeddings_late(chunk_contents)\n",
    "\n",
    "    chunk_count = len(chunks)\n",
    "\n",
    "    points: list[models.PointStruct] = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        id = uuid.uuid5(uuid.NAMESPACE_DNS, f\"{doc['publishDate']}-${i}\")\n",
    "\n",
    "        chunk[\"chunk_index\"] = i\n",
    "        chunk[\"chunk_count\"] = chunk_count\n",
    "\n",
    "        points.append(models.PointStruct(\n",
    "            id=id,\n",
    "            payload=chunk,\n",
    "            vector={\n",
    "                \"dense\": chunk_embeddings[i],\n",
    "                \"splade\": sparse_embeddings[i].as_object(),\n",
    "                \"late\": late_embeddings[i]\n",
    "            }\n",
    "        ))\n",
    "\n",
    "    batch_size = 25\n",
    "    for i in range(0, len(points), batch_size):\n",
    "        batch = points[i:i + batch_size]\n",
    "        client.upsert(\n",
    "            collection_name=\"news\",\n",
    "            wait=True,\n",
    "            points=batch,\n",
    "        )\n",
    "\n",
    "    print(f\"success index {idx+start_idx}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
